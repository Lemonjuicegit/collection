{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import pdfplumber\n",
        "import struct\n",
        "from uuid import uuid4\n",
        "from scipy.optimize import curve_fit\n",
        "from pathlib import Path\n",
        "from shapely import MultiLineString, Point\n",
        "from docx import Document\n",
        "from docx.table import _Cell\n",
        "from package.utils import re_json\n",
        "\n",
        "# from routers.collection.service import deviceIpService, dataItemService, routerService\n",
        "import redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 开州TBBH重新编号\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath = r\"E:\\工作文档\\开州项目\\编号.xlsx\"\n",
        "df = pd.read_excel(datapath)\n",
        "df = df.fillna(\"\")\n",
        "TBBH_list = set(df[\"TBBH\"].values)\n",
        "for tbbh in TBBH_list:\n",
        "    data = df[df[\"TBBH\"] == tbbh]\n",
        "    xh_list = list({int(v) for v in data[\"xh\"].values if v != \"\"})\n",
        "    xh = 0\n",
        "    if xh_list:\n",
        "        xh_max = max(xh_list)\n",
        "        for i in xh_list:\n",
        "            data_xh = data[data[\"xh\"] == i]\n",
        "            for index, row in data_xh.iterrows():\n",
        "                if xh == 0:\n",
        "                    xh += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    df.loc[index, \"xh\"] = xh + xh_max\n",
        "                    xh += 1\n",
        "        xh = 0\n",
        "    else:\n",
        "        for index, row in data.iterrows():\n",
        "            xh += 1\n",
        "            df.loc[index, \"xh\"] = xh\n",
        "        xh = 0\n",
        "\n",
        "df.to_excel(r\"E:\\工作文档\\开州项目\\重新编号.xlsx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 找出最大面积的要素\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel(r\"C:\\Users\\Administrator\\Desktop\\面积最大.xlsx\")\n",
        "dfdata = pd.DataFrame(columns=df.columns)\n",
        "CGBH = set(df.CGBH.values)\n",
        "for v in CGBH:\n",
        "    CGBH_temp = df[df.CGBH == v]\n",
        "    Area = CGBH_temp.Area.values\n",
        "    Area_max = max([value for value in Area])\n",
        "    res = CGBH_temp[CGBH_temp.Area == Area_max].values[0]\n",
        "    dfdata.loc[dfdata.shape[0]] = [*res]\n",
        "dfdata.to_excel(r\"E:\\工作文档\\qita\\台账过程\\新建文件夹\\aa.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 检测道路线相邻地类编码\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "gdbpath = r\"E:\\工作文档\\云阳县城市国土空间监测\\gdb数据库\\道路拓扑.gdb\"\n",
        "save = r\"E:\\工作文档\\云阳县城市国土空间监测\"\n",
        "LVLL = gpd.read_file(gdbpath, layer=\"LVLL\")\n",
        "LRDL = gpd.read_file(gdbpath, layer=\"LRDL\")\n",
        "LCTL = gpd.read_file(gdbpath, layer=\"LCTL\")\n",
        "hb = gpd.read_file(gdbpath, layer=\"合并\")\n",
        "\n",
        "\n",
        "def inspect(shp, savapath):\n",
        "    resdf = gpd.GeoDataFrame(columns=[\"dlbm\", \"x\", \"y\", \"add\", \"geometry\"])\n",
        "    for _, row in shp.iterrows():\n",
        "        if type(row.geometry) == MultiLineString:\n",
        "            point_xy = row.geometry.geoms[0].xy\n",
        "        else:\n",
        "            point_xy = row.geometry.xy\n",
        "        po1 = Point(point_xy[0][0], point_xy[1][0])\n",
        "        po2 = Point(point_xy[0][-1], point_xy[1][-1])\n",
        "        resdf.loc[resdf.shape[0]] = [\n",
        "            row.RN,\n",
        "            point_xy[0][0],\n",
        "            point_xy[1][0],\n",
        "            f\"{point_xy[0][0]}{point_xy[1][0]}\",\n",
        "            po1,\n",
        "        ]\n",
        "        resdf.loc[resdf.shape[0]] = [\n",
        "            row.RN,\n",
        "            point_xy[0][-1],\n",
        "            point_xy[1][-1],\n",
        "            f\"{point_xy[0][-1]}{point_xy[1][-1]}\",\n",
        "            po2,\n",
        "        ]\n",
        "    resdf.crs = shp.crs\n",
        "    resdf.to_file(savapath)\n",
        "\n",
        "\n",
        "inspect(hb, os.path.join(save, \"检查.shp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 计算文件夹文件大小\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_folder_size(folder_path):\n",
        "    # 计算文件夹大小\n",
        "    total_size = 0\n",
        "    for path, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(path, file)\n",
        "            total_size += os.path.getsize(file_path)\n",
        "    return total_size\n",
        "\n",
        "\n",
        "a = get_folder_size(r\"C:\\Users\\Administrator\\AppData\\Local\")\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 高精度求和\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TopAdd(DictoAdjs, MJtoAdjs, AddNums):\n",
        "    try:\n",
        "        Count = abs(MJtoAdjs)\n",
        "        # arcpy.AddMessage(DicLen)\n",
        "        if MJtoAdjs < 0:\n",
        "            AddNums = -AddNums\n",
        "        i = 0\n",
        "        for key in DictoAdjs.keys():\n",
        "            if i < Count:\n",
        "                # if key == u'370982211000059509':\n",
        "                #    arcpy.AddMessage(str(DictoAdjs[key][0])+ \" TopAdd \" + str(Decimal(AddNums)))\n",
        "                DictoAdjs[key][0] = (\n",
        "                    Decimal(DictoAdjs[key][0]) + Decimal(AddNums)\n",
        "                ).quantize(Decimal(\"0.00\"))\n",
        "                i += 1\n",
        "            else:\n",
        "                break\n",
        "        # arcpy.AddMessage(DictoAdjs)\n",
        "        return DictoAdjs\n",
        "    except Exception as e:\n",
        "        arcpy.AddMessage(\"出错\" + e.message)\n",
        "        return DictoAdjs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 拟合\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_func(x, A, B, C, D):\n",
        "    # 拟合函数\n",
        "    return A * (x**3) + B * (x**2) + C * x + D\n",
        "\n",
        "\n",
        "# 创建数据点\n",
        "x_data = np.array(\n",
        "    [116.35, 116.65, 116.95, 117.2, 117.4, 117.55, 117.7, 117.75, 117.8, 117.85]\n",
        ")\n",
        "y_data = np.array([1, 1.1, 1.21, 1.35, 1.45, 1.58, 1.7, 1.82, 1.91, 2.12])\n",
        "\n",
        "# 拟合数据\n",
        "popt, pcov = curve_fit(log_func, x_data, y_data)\n",
        "\n",
        "# 绘制数据和拟合曲线\n",
        "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
        "plt.rcParams[\"axes.unicode_minus\"] = False\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x_data, y_data, label=r\"数据点\", color=\"blue\")\n",
        "plt.plot(x_data, log_func(x_data, *popt), \"r-\", label=\"拟合曲线\")\n",
        "plt.legend()\n",
        "plt.title(\"水深与面积拟合\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## pdf转word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_tables_from_pdf(pdf_path):\n",
        "    tables = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            table_data = page.extract_tables()\n",
        "            if table_data:\n",
        "                tables.extend(table_data)\n",
        "    return tables\n",
        "\n",
        "\n",
        "def add_table_to_docx(doc, table_data):\n",
        "    table = doc.add_table(rows=len(table_data), cols=len(table_data[0]))\n",
        "    for i, row in enumerate(table_data):\n",
        "        for j, cell_data in enumerate(row):\n",
        "            cell: _Cell = table.cell(i, j)\n",
        "            cell.text = str(cell_data)\n",
        "    return table\n",
        "\n",
        "\n",
        "def pdf_to_word(pdf_path, word_path):\n",
        "    doc = Document()\n",
        "    tables = extract_tables_from_pdf(pdf_path)\n",
        "    for table_data in tables:\n",
        "        add_table_to_docx(doc, table_data)\n",
        "    doc.save(word_path)\n",
        "\n",
        "\n",
        "# 指定PDF文件和输出的Word文件路径\n",
        "pdf_file = r\"E:\\工作文档\\资料标准文件\\303-自然资源监测培训ppt及材料\\5.pdf\"\n",
        "docx_file = r\"E:\\工作文档\\资料标准文件\\303-自然资源监测培训ppt及材料\\5-2.docx\"\n",
        "\n",
        "# 调用函数进行转换\n",
        "pdf_to_word(pdf_file, docx_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from package.pdf.setup import pdf_to_images\n",
        "\n",
        "pdfpath = Path(r\"E:\\工作文档\\万盛\\新建文件夹\")\n",
        "pdf_to_images(pdfpath, rf\"E:\\工作文档\\万盛\\新建文件夹 (2)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_data_path = Path(r\"D:\\深度学习\\MNIST数据集\\train-images.idx3-ubyte\").read_bytes()\n",
        "labels_data_path = Path(r\"D:\\深度学习\\MNIST数据集\\train-labels.idx1-ubyte\").read_bytes()\n",
        "images_data = np.frombuffer(images_data_path, np.uint8)\n",
        "labels_data = np.frombuffer(labels_data_path, np.uint8)\n",
        "data = images_data[16:].reshape([-1, 28])\n",
        "plt.matshow(data[28:56], cmap=plt.get_cmap(\"gray\"))\n",
        "plt.show()\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "menuitemURL = Path(Path.cwd()) / \"menuitemURL.json\"\n",
        "\n",
        "\n",
        "def getRouterName():\n",
        "    menuitem = json.loads(menuitemURL.read_text(encoding=\"utf-8\"))\n",
        "    routerName = [key for key in menuitem]\n",
        "    return routerName\n",
        "\n",
        "\n",
        "print(getRouterName())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    # 监督数据是one-hot-vector的情况下，转换为正确解标签的索引\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "\n",
        "a = np.array([3, 54, 3])\n",
        "res = cross_entropy_error(a, np.array([4, 6, 7]))\n",
        "res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 读取图片信息\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import piexif\n",
        "\n",
        "\n",
        "def get_gps_info(image_path):\n",
        "    # 打开图片\n",
        "    img = Image.open(image_path)\n",
        "    # 获取Exif信息\n",
        "    exif_dict = piexif.load(img.info[\"exif\"])\n",
        "\n",
        "    if \"GPS\" in exif_dict:\n",
        "        gps_info = exif_dict[\"GPS\"]\n",
        "\n",
        "        # 解析经纬度\n",
        "        def dms_to_dd(dms, ref):\n",
        "            degrees = dms[0][0] / dms[0][1]\n",
        "            minutes = dms[1][0] / dms[1][1] / 60.0\n",
        "            seconds = dms[2][0] / dms[2][1] / 3600.0\n",
        "\n",
        "            if ref in [\"S\", \"W\"]:\n",
        "                degrees = -degrees\n",
        "                minutes = -minutes\n",
        "                seconds = -seconds\n",
        "\n",
        "            return round(degrees + minutes + seconds, 7)\n",
        "\n",
        "        lat = dms_to_dd(gps_info[2], gps_info[1])\n",
        "        lon = dms_to_dd(gps_info[4], gps_info[3])\n",
        "\n",
        "        print(f\"纬度: {lat}, 经度: {lon}\")\n",
        "    else:\n",
        "        print(\"没有找到GPS信息\")\n",
        "\n",
        "\n",
        "# 调用函数并传入图片路径\n",
        "get_gps_info(r\"C:\\Users\\Administrator\\Desktop\\IMG_20240920_163336.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## las点云数据转坐标串数据\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 处理点云数据\n",
        "import laspy\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "path_ = r\"E:\\工作文档\\万州区\\水资源\\点云\"\n",
        "\n",
        "files = Path(path_).glob(\"*.las\")\n",
        "\n",
        "for file in files:\n",
        "    with open(r\"E:\\工作文档\\万州区\\水资源\\点云\\点云.xyz\", \"a\") as f:\n",
        "        las = laspy.read(file)\n",
        "        for i in range(len(las.x)):\n",
        "            xyz = f\"{las.x[i]},{las.y[i]},{las.z[i]}\"\n",
        "            f.write(xyz + \"\\n\")\n",
        "\n",
        "\n",
        "# 读取LAS文件\n",
        "file_path = r\"E:\\工作文档\\万州区\\水资源\\点云\\鱼背山1地面点.las\"\n",
        "las = laspy.read(file_path)\n",
        "\n",
        "\n",
        "# 访问点云数据\n",
        "points = np.vstack((las.x, las.y, las.z)).transpose()\n",
        "\n",
        "# 打印前5个点的坐标\n",
        "print(points[:5])\n",
        "\n",
        "# 访问其他属性\n",
        "intensity = las.intensity\n",
        "classification = las.classification\n",
        "return_number = las.return_number\n",
        "number_of_returns = las.number_of_returns\n",
        "\n",
        "# 打印前5个点的强度和分类\n",
        "print(intensity[:5])\n",
        "print(classification[:5])\n",
        "\n",
        "# 创建新的LAS文件\n",
        "new_file_path = \"path/to/your/new_file.las\"\n",
        "header = laspy.LasHeader(point_format=las.point_format, version=las.version)\n",
        "with laspy.open(new_file_path, mode=\"w\", header=header) as writer:\n",
        "    writer.write_points(las.points)\n",
        "\n",
        "print(f\"新文件已保存到 {new_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 处理点云数据\n",
        "import laspy\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "path_ = r\"E:\\工作文档\\万州区\\水资源\\点云\"\n",
        "\n",
        "files = Path(path_).glob(\"*.las\")\n",
        "# files = [Path(r\"E:\\工作文档\\万州区\\水资源\\点云\\鱼背山6地面点.las\")]\n",
        "for file in files:\n",
        "    with open(r\"E:\\工作文档\\万州区\\水资源\\点云\\点云2.xyz\", \"a\") as f:\n",
        "        las = laspy.read(file)\n",
        "        for i in range(len(las.x)):\n",
        "            xyz = f\"{round(las.x[i] + 36000000, 2)},{round(las.y[i], 2)},{round(las.z[i], 2)}\"\n",
        "            f.write(xyz + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 计算平均值\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_excel(r\"E:\\工作文档\\梁平区\\计算水深平均值.xlsx\")\n",
        "sh = {}\n",
        "\n",
        "\n",
        "def convert(row):\n",
        "    if row.code not in sh:\n",
        "        sh[row.code] = []\n",
        "    sh[row.code].append(float(row.sh))\n",
        "\n",
        "\n",
        "df.apply(convert, axis=1)\n",
        "sh_pj = pd.DataFrame(columns=[\"code\", \"sh\"])\n",
        "for i in sh:\n",
        "    sh_pj.loc[len(sh_pj)] = [i, sum(sh[i]) / len(sh[i])]\n",
        "sh_pj.to_excel(r\"E:\\工作文档\\梁平区\\计算水深平均值2.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Degree(d=0, f=0, m=0):\n",
        "    return d + f / 60 + m / 3600\n",
        "\n",
        "\n",
        "def sec(d=0, f=0, m=0):\n",
        "    return d * 3600 + f * 60 + m\n",
        "\n",
        "\n",
        "def degrees_to_dms(degrees):\n",
        "    d = int(degrees)\n",
        "    minutes_t = (degrees - d) * 60\n",
        "    m = int(minutes_t)\n",
        "    s = (minutes_t - m) * 60\n",
        "    return [d, m, s]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TFH(latitude, longitude):\n",
        "    million_latitude = [chr(i) for i in range(65, 91)]\n",
        "    million_row = million_latitude[int(longitude[0] / 4)]\n",
        "    million_col = int(latitude[0] / 6) + 1\n",
        "    wd = sec(*longitude)  # 经度十进制值\n",
        "    jd = sec(*latitude)  # 纬度十进制值\n",
        "    w_row = str(96 - int((wd - int(wd / 14400) * 14400) / 150) + 1)\n",
        "    w_col = str(int((jd - int(jd / 21600) * 21600) / 225) + 1)\n",
        "    row_h = \"0\" * (3 - len(w_row))\n",
        "    col_h = \"0\" * (3 - len(w_col))\n",
        "    return f\"{million_row}{million_col}G{row_h}{w_row}{col_h}{w_col}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 开州项目重新编号\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "datapath = r\"E:\\工作文档\\开州项目\\编号.xlsx\"\n",
        "df = pd.read_excel(datapath)\n",
        "df = df.fillna(\"\")\n",
        "TBBH_list = set(df[\"TBBH\"].values)\n",
        "for tbbh in TBBH_list:\n",
        "    data = df[df[\"TBBH\"] == tbbh]\n",
        "    xh_list = list({int(v) for v in data[\"xh\"].values if v != \"\"})\n",
        "    xh = 0\n",
        "    if xh_list:\n",
        "        xh_max = max(xh_list)\n",
        "        for i in xh_list:\n",
        "            data_xh = data[data[\"xh\"] == i]\n",
        "            for index, row in data_xh.iterrows():\n",
        "                if xh == 0:\n",
        "                    xh += 1\n",
        "                    continue\n",
        "                else:\n",
        "                    df.loc[index, \"xh\"] = xh + xh_max\n",
        "                    xh += 1\n",
        "        xh = 0\n",
        "    else:\n",
        "        for index, row in data.iterrows():\n",
        "            xh += 1\n",
        "            df.loc[index, \"xh\"] = xh\n",
        "        xh = 0\n",
        "\n",
        "df.to_excel(r\"E:\\工作文档\\开州项目\\重新编号.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## redis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'bar'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r = redis.StrictRedis(host=\"localhost\", port=6379, db=0)\n",
        "r.set(\"foo\", \"bar\")\n",
        "r.get(\"foo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 6), (2, 7), (3, 8), (4, 9), (5, 10)]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [1, 2, 3, 4, 5]\n",
        "b = [6, 7, 8, 9, 10]\n",
        "list(zip(a, b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from package.pdf.setup import pdf_to_images\n",
        "import os\n",
        "\n",
        "pathjpg = r\"E:\\工作文档\\永川低效园林的开发\\仙龙镇\\仙龙镇\"\n",
        "filename = os.listdir(pathjpg)\n",
        "# for name in filename:\n",
        "#     _name = name.split(\".\")[0]\n",
        "pdf_to_images(\n",
        "    r\"E:\\工作文档\\永川低效园林的开发\\20250402黄瓜山改\",\n",
        "    r\"E:\\工作文档\\永川低效园林的开发\\20250402黄瓜山改JPG\",\n",
        ")\n",
        "# pdf_to_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from package.pdf.setup import pdf_to_images\n",
        "\n",
        "pdf_to_images(\n",
        "    r\"E:\\工作文档\\永川低效园林的开发\\20250402黄瓜山\",\n",
        "    r\"E:\\工作文档\\永川低效园林的开发\\20250402黄瓜山JBG\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from routers.collection.service.routerService import routerService\n",
        "res = routerService.select({\"router_type\": \"collection\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[RouterDO(title='项目四组', id=4, name='23c0ad0c52484e7c9099e7088facad74', path='xm4', router_type='collection'),\n",
              " RouterDO(title='项目跟踪明细', id=11, name='57df458ecd2848ed85aee5ab36e7d4c2', path='jylsgd', router_type='collection')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
